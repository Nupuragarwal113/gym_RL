{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8xg31Ugb0qeqHWVar9tud"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"hNrap4RxQDy1","executionInfo":{"status":"ok","timestamp":1750102813226,"user_tz":-330,"elapsed":18280,"user":{"displayName":"Nupur Agarwal","userId":"05958640028434040813"}},"outputId":"bab75f9a-89a9-4943-b5b0-b75e3dc1a62b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.23.5\n","  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n","db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","bigframes 2.6.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n","blosc2 3.3.4 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"4f5035896f244d9c8670f7481af71655"}},"metadata":{}}],"source":["!pip install numpy==1.23.5 --upgrade --force-reinstall"]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from collections import deque\n","\n","# Create environment using default API (old style)\n","env = gym.make(\"CartPole-v1\")\n","state_size = env.observation_space.shape[0]\n","action_size = env.action_space.n\n","\n","# Hyperparameters\n","gamma = 0.99\n","epsilon = 1.0\n","epsilon_min = 0.01\n","epsilon_decay = 0.995\n","lr = 0.001\n","episodes = 100\n","batch_size = 64\n","memory = deque(maxlen=2000)\n","\n","# DQN model\n","class DQN(nn.Module):\n","    def __init__(self, state_size, action_size):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(state_size, 24)\n","        self.fc2 = nn.Linear(24, 24)\n","        self.out = nn.Linear(24, action_size)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        return self.out(x)\n","\n","model = DQN(state_size, action_size)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","loss_fn = nn.MSELoss()\n","\n","# Choose action (epsilon-greedy)\n","def act(state):\n","    if np.random.rand() <= epsilon:\n","        return random.randrange(action_size)\n","    state_tensor = torch.FloatTensor(state)\n","    with torch.no_grad():\n","        q_values = model(state_tensor)\n","    return torch.argmax(q_values).item()\n","\n","# Train on experience replay\n","def replay():\n","    global epsilon\n","    if len(memory) < batch_size:\n","        return\n","    minibatch = random.sample(memory, batch_size)\n","    for state, action, reward, next_state, done in minibatch:\n","        target = reward\n","        if not done:\n","            next_q = model(torch.FloatTensor(next_state))\n","            target += gamma * torch.max(next_q).item()\n","        current_q = model(torch.FloatTensor(state))[0][action]\n","        loss = loss_fn(current_q, torch.tensor(target))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    if epsilon > epsilon_min:\n","        epsilon *= epsilon_decay\n","\n","# Training loop\n","for episode in range(episodes):\n","    state = env.reset()\n","    state = np.reshape(state, [1, state_size])\n","    total_reward = 0\n","    for t in range(200):\n","        action = act(state)\n","        next_state, reward, done, _ = env.step(action)\n","        next_state = np.reshape(next_state, [1, state_size])\n","        memory.append((state, action, reward, next_state, done))\n","        state = next_state\n","        total_reward += reward\n","        if done:\n","            break\n","        replay()\n","    print(f\"Episode {episode+1}/{episodes} - Score: {total_reward} - Epsilon: {epsilon:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PAf-vTPvQJzj","executionInfo":{"status":"ok","timestamp":1750102950150,"user_tz":-330,"elapsed":136813,"user":{"displayName":"Nupur Agarwal","userId":"05958640028434040813"}},"outputId":"63f359df-e478-49c4-c714-569fac399261"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]},{"output_type":"stream","name":"stdout","text":["Episode 1/100 - Score: 23.0 - Epsilon: 1.00\n","Episode 2/100 - Score: 44.0 - Epsilon: 0.99\n","Episode 3/100 - Score: 17.0 - Epsilon: 0.91\n","Episode 4/100 - Score: 18.0 - Epsilon: 0.83\n","Episode 5/100 - Score: 41.0 - Epsilon: 0.68\n","Episode 6/100 - Score: 20.0 - Epsilon: 0.62\n","Episode 7/100 - Score: 14.0 - Epsilon: 0.58\n","Episode 8/100 - Score: 12.0 - Epsilon: 0.55\n","Episode 9/100 - Score: 12.0 - Epsilon: 0.52\n","Episode 10/100 - Score: 9.0 - Epsilon: 0.50\n","Episode 11/100 - Score: 18.0 - Epsilon: 0.46\n","Episode 12/100 - Score: 23.0 - Epsilon: 0.41\n","Episode 13/100 - Score: 13.0 - Epsilon: 0.39\n","Episode 14/100 - Score: 9.0 - Epsilon: 0.37\n","Episode 15/100 - Score: 21.0 - Epsilon: 0.34\n","Episode 16/100 - Score: 15.0 - Epsilon: 0.31\n","Episode 17/100 - Score: 9.0 - Epsilon: 0.30\n","Episode 18/100 - Score: 9.0 - Epsilon: 0.29\n","Episode 19/100 - Score: 11.0 - Epsilon: 0.28\n","Episode 20/100 - Score: 13.0 - Epsilon: 0.26\n","Episode 21/100 - Score: 11.0 - Epsilon: 0.25\n","Episode 22/100 - Score: 9.0 - Epsilon: 0.24\n","Episode 23/100 - Score: 11.0 - Epsilon: 0.23\n","Episode 24/100 - Score: 11.0 - Epsilon: 0.21\n","Episode 25/100 - Score: 11.0 - Epsilon: 0.20\n","Episode 26/100 - Score: 10.0 - Epsilon: 0.20\n","Episode 27/100 - Score: 8.0 - Epsilon: 0.19\n","Episode 28/100 - Score: 9.0 - Epsilon: 0.18\n","Episode 29/100 - Score: 11.0 - Epsilon: 0.17\n","Episode 30/100 - Score: 9.0 - Epsilon: 0.17\n","Episode 31/100 - Score: 11.0 - Epsilon: 0.16\n","Episode 32/100 - Score: 10.0 - Epsilon: 0.15\n","Episode 33/100 - Score: 9.0 - Epsilon: 0.14\n","Episode 34/100 - Score: 9.0 - Epsilon: 0.14\n","Episode 35/100 - Score: 13.0 - Epsilon: 0.13\n","Episode 36/100 - Score: 9.0 - Epsilon: 0.13\n","Episode 37/100 - Score: 13.0 - Epsilon: 0.12\n","Episode 38/100 - Score: 9.0 - Epsilon: 0.11\n","Episode 39/100 - Score: 9.0 - Epsilon: 0.11\n","Episode 40/100 - Score: 10.0 - Epsilon: 0.10\n","Episode 41/100 - Score: 9.0 - Epsilon: 0.10\n","Episode 42/100 - Score: 30.0 - Epsilon: 0.09\n","Episode 43/100 - Score: 35.0 - Epsilon: 0.07\n","Episode 44/100 - Score: 10.0 - Epsilon: 0.07\n","Episode 45/100 - Score: 9.0 - Epsilon: 0.07\n","Episode 46/100 - Score: 9.0 - Epsilon: 0.06\n","Episode 47/100 - Score: 9.0 - Epsilon: 0.06\n","Episode 48/100 - Score: 10.0 - Epsilon: 0.06\n","Episode 49/100 - Score: 13.0 - Epsilon: 0.06\n","Episode 50/100 - Score: 9.0 - Epsilon: 0.05\n","Episode 51/100 - Score: 10.0 - Epsilon: 0.05\n","Episode 52/100 - Score: 34.0 - Epsilon: 0.04\n","Episode 53/100 - Score: 8.0 - Epsilon: 0.04\n","Episode 54/100 - Score: 9.0 - Epsilon: 0.04\n","Episode 55/100 - Score: 10.0 - Epsilon: 0.04\n","Episode 56/100 - Score: 9.0 - Epsilon: 0.04\n","Episode 57/100 - Score: 8.0 - Epsilon: 0.04\n","Episode 58/100 - Score: 22.0 - Epsilon: 0.03\n","Episode 59/100 - Score: 11.0 - Epsilon: 0.03\n","Episode 60/100 - Score: 10.0 - Epsilon: 0.03\n","Episode 61/100 - Score: 10.0 - Epsilon: 0.03\n","Episode 62/100 - Score: 10.0 - Epsilon: 0.03\n","Episode 63/100 - Score: 9.0 - Epsilon: 0.03\n","Episode 64/100 - Score: 10.0 - Epsilon: 0.02\n","Episode 65/100 - Score: 9.0 - Epsilon: 0.02\n","Episode 66/100 - Score: 9.0 - Epsilon: 0.02\n","Episode 67/100 - Score: 9.0 - Epsilon: 0.02\n","Episode 68/100 - Score: 9.0 - Epsilon: 0.02\n","Episode 69/100 - Score: 11.0 - Epsilon: 0.02\n","Episode 70/100 - Score: 35.0 - Epsilon: 0.02\n","Episode 71/100 - Score: 16.0 - Epsilon: 0.02\n","Episode 72/100 - Score: 10.0 - Epsilon: 0.01\n","Episode 73/100 - Score: 10.0 - Epsilon: 0.01\n","Episode 74/100 - Score: 36.0 - Epsilon: 0.01\n","Episode 75/100 - Score: 28.0 - Epsilon: 0.01\n","Episode 76/100 - Score: 10.0 - Epsilon: 0.01\n","Episode 77/100 - Score: 13.0 - Epsilon: 0.01\n","Episode 78/100 - Score: 12.0 - Epsilon: 0.01\n","Episode 79/100 - Score: 15.0 - Epsilon: 0.01\n","Episode 80/100 - Score: 9.0 - Epsilon: 0.01\n","Episode 81/100 - Score: 17.0 - Epsilon: 0.01\n","Episode 82/100 - Score: 15.0 - Epsilon: 0.01\n","Episode 83/100 - Score: 18.0 - Epsilon: 0.01\n","Episode 84/100 - Score: 18.0 - Epsilon: 0.01\n","Episode 85/100 - Score: 15.0 - Epsilon: 0.01\n","Episode 86/100 - Score: 19.0 - Epsilon: 0.01\n","Episode 87/100 - Score: 12.0 - Epsilon: 0.01\n","Episode 88/100 - Score: 12.0 - Epsilon: 0.01\n","Episode 89/100 - Score: 14.0 - Epsilon: 0.01\n","Episode 90/100 - Score: 15.0 - Epsilon: 0.01\n","Episode 91/100 - Score: 18.0 - Epsilon: 0.01\n","Episode 92/100 - Score: 17.0 - Epsilon: 0.01\n","Episode 93/100 - Score: 12.0 - Epsilon: 0.01\n","Episode 94/100 - Score: 24.0 - Epsilon: 0.01\n","Episode 95/100 - Score: 16.0 - Epsilon: 0.01\n","Episode 96/100 - Score: 13.0 - Epsilon: 0.01\n","Episode 97/100 - Score: 17.0 - Epsilon: 0.01\n","Episode 98/100 - Score: 22.0 - Epsilon: 0.01\n","Episode 99/100 - Score: 13.0 - Epsilon: 0.01\n","Episode 100/100 - Score: 15.0 - Epsilon: 0.01\n"]}]}]}